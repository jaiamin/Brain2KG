{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jamino/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import ollama\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alan Shepard was born on Nov 18, 1923 and selected by NASA in 1959.',\n",
       " 'Alan Shepard was a member of the Apollo 14 crew.']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert text to sentences\n",
    "\n",
    "raw_text = \"\"\"\\\n",
    "Alan Shepard was born on Nov 18, 1923 and selected by NASA in 1959. Alan Shepard was a member of the Apollo 14 crew. \\\n",
    "\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(raw_text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alan Shepard was born on Nov 18, 1923 and selected by NASA in 1959.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sentences[0] as main text for now\n",
    "\n",
    "text = sentences[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "def get_embedding(model: str, sentence: str, task=None):\n",
    "    if task != None:\n",
    "        sentence = get_detailed_instruct(task, sentence)\n",
    "        \n",
    "    embeddings = ollama.embeddings(\n",
    "        model=model,\n",
    "        prompt=sentence\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "def parse_raw_triplets(raw_triplets: str):\n",
    "    matches = re.findall(r'\\[(.+?)\\]', raw_triplets)\n",
    "    structured_triplets = [[triplet.strip() for triplet in group.split('|')] for group in matches]\n",
    "    \n",
    "    print('----------')\n",
    "    print('RAW:')\n",
    "    print(raw_triplets)\n",
    "    print('----------')\n",
    "    return structured_triplets\n",
    "\n",
    "def parse_relation_definition(raw_definitions: str):\n",
    "    descriptions = raw_definitions.split('\\n')\n",
    "    relation_definitions_dict = {}\n",
    "\n",
    "    for description in descriptions:\n",
    "        if ':' not in description:\n",
    "            continue\n",
    "        index_of_colon = description.index(':')\n",
    "        relation = description[:index_of_colon].strip()\n",
    "\n",
    "        relation_description = description[:index_of_colon + 1 :].strip()\n",
    "\n",
    "        relation_definitions_dict[relation] = relation_description\n",
    "    \n",
    "    print('----------')\n",
    "    print('RAW:')\n",
    "    print(raw_definitions)\n",
    "    print('----------')\n",
    "    return raw_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriplesExtractor:\n",
    "    def __init__(self, model: str = None) -> None:\n",
    "        assert model is not None \n",
    "        self.model = model\n",
    "\n",
    "    def extract(\n",
    "        self,\n",
    "        input_text_str: str,\n",
    "        prompt_template_str: str,\n",
    "        few_shot_examples_str: str = None,\n",
    "    ) -> list[list[str]]:\n",
    "        if not few_shot_examples_str:\n",
    "            filled_prompt = prompt_template_str.format_map(\n",
    "                {\n",
    "                    'input_text': input_text_str,    \n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            filled_prompt = prompt_template_str.format_map(\n",
    "                {\n",
    "                    'few_shot_examples': few_shot_examples_str,\n",
    "                    'input_text': input_text_str,\n",
    "                }\n",
    "            )\n",
    "        messages = [{'role': 'user', 'content': filled_prompt}]\n",
    "        completion = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "        )['message']['content']\n",
    "        extracted_triplets_list = parse_raw_triplets(completion)\n",
    "        return extracted_triplets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "RAW:\n",
      "[Alan Shepard | wasBornOn | November 18, 1923]\n",
      "[Alan Shepard | wasSelectedBy | NASA]\n",
      "[Alan Shepard | isEqualTo | Astronaut]\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Alan Shepard', 'wasBornOn', 'November 18, 1923'],\n",
       " ['Alan Shepard', 'wasSelectedBy', 'NASA'],\n",
       " ['Alan Shepard', 'isEqualTo', 'Astronaut']]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = TriplesExtractor(model='llama3.1')\n",
    "triples = extractor.extract(\n",
    "    input_text_str=text,\n",
    "    prompt_template_str=open('prompt_templates/oie_zsp_template.txt').read(),\n",
    ")\n",
    "triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaDefiner:\n",
    "    def __init__(self, model: str = None) -> None:\n",
    "        assert model is not None\n",
    "        self.model = model\n",
    "\n",
    "    def define_schema(\n",
    "            self,\n",
    "            input_text_str: str,\n",
    "            extracted_triplets_list: list[list[str]],\n",
    "            prompt_template_str: str,\n",
    "            few_shot_examples_str: str = None,\n",
    "    ) -> list[list[str]]:\n",
    "        \n",
    "        relations_present = set()\n",
    "        for t in extracted_triplets_list:\n",
    "            relations_present.add(t[1])\n",
    "        \n",
    "        if not few_shot_examples_str:\n",
    "            filled_prompt = prompt_template_str.format_map(\n",
    "                {\n",
    "                    'text': input_text_str,\n",
    "                    'relations': relations_present,\n",
    "                    'triples': extracted_triplets_list,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            filled_prompt = prompt_template_str.format_map(\n",
    "                {\n",
    "                    'few_shot_examples': few_shot_examples_str,\n",
    "                    'text': input_text_str,\n",
    "                    'relations': relations_present,\n",
    "                    'triples': extracted_triplets_list,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        messages = [{'role': 'user', 'content': filled_prompt}]\n",
    "        completion = ollama.chat(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "        )['message']['content']\n",
    "        relation_definition_dict = parse_relation_definition(completion)\n",
    "        return relation_definition_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "RAW:\n",
      "Here are the descriptions for each relation:\n",
      "\n",
      "* `wasBornOn`: Indicates that an entity had their birth on a specific date.\n",
      "* `wasSelectedBy`: Indicates that one entity selected another entity for some purpose or position.\n",
      "* `isEqualTo`: Indicates that two entities have the same value or identity.\n",
      "----------\n",
      "Here are the descriptions for each relation:\n",
      "\n",
      "* `wasBornOn`: Indicates that an entity had their birth on a specific date.\n",
      "* `wasSelectedBy`: Indicates that one entity selected another entity for some purpose or position.\n",
      "* `isEqualTo`: Indicates that two entities have the same value or identity.\n"
     ]
    }
   ],
   "source": [
    "definer = SchemaDefiner(model='llama3.1')\n",
    "definitions = definer.define_schema(\n",
    "    input_text_str=text,\n",
    "    extracted_triplets_list=triples,\n",
    "    prompt_template_str=open('prompt_templates/sd_zsp_template.txt').read(),\n",
    ")\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaRetriever:\n",
    "    def __init__(self, target_schema_dict: dict, embedding_model) -> None:\n",
    "        self.target_schema_dict = target_schema_dict\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        self.target_schema_embedding_dict = {}\n",
    "\n",
    "        for relation, relation_definition in target_schema_dict.items():\n",
    "            embedding = get_embedding(\n",
    "                model=self.embedding_model,\n",
    "                sentence=relation_definition\n",
    "            )\n",
    "            self.target_schema_embedding_dict[relation] = embedding\n",
    "\n",
    "    def update_schema_embedding_dict(self):\n",
    "        for relation, relation_definition in self.target_schema_dict.items():\n",
    "            if relation in self.target_schema_embedding_dict:\n",
    "                continue\n",
    "            embedding = get_embedding(\n",
    "                model=self.embedding_model,\n",
    "                sentence=relation_definition\n",
    "            )\n",
    "            self.target_schema_embedding_dict[relation] = embedding\n",
    "\n",
    "    def retrieve_relevant_relations(self, query_input_text: str, top_k=10):\n",
    "        target_relation_list = list(self.target_schema_embedding_dict.keys())\n",
    "        target_relation_embedding_list = list(self.target_schema_embedding_dict.values())\n",
    "\n",
    "        query_embedding = get_embedding(\n",
    "            model=self.embedding_model,\n",
    "            sentence=query_input_text,\n",
    "            task='Retrieve descriptions of relations that are present in the given text.',\n",
    "        )['embedding']\n",
    "\n",
    "        # DELETE\n",
    "        print('SHAPE1', np.array([query_embedding]).shape)\n",
    "        print('SHAPE2', np.array(target_relation_embedding_list).T.shape)\n",
    "\n",
    "        scores = np.array([query_embedding]) @ np.array(target_relation_embedding_list).T\n",
    "\n",
    "        scores = scores[0]\n",
    "        highest_scores_indices = np.argsort(-scores)\n",
    "\n",
    "        return [target_relation_list[idx] for idx in highest_scores_indices[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE1 (1, 4096)\n",
      "SHAPE2 (159,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 159 is different from 4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m         target_schema_dict[row[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m retriever \u001b[38;5;241m=\u001b[39m SchemaRetriever(\n\u001b[1;32m      8\u001b[0m     target_schema_dict\u001b[38;5;241m=\u001b[39mtarget_schema_dict,\n\u001b[1;32m      9\u001b[0m     embedding_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3.1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_relevant_relations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_input_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mThis indicates a specific date related to when an individual was born.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[173], line 39\u001b[0m, in \u001b[0;36mSchemaRetriever.retrieve_relevant_relations\u001b[0;34m(self, query_input_text, top_k)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHAPE1\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39marray([query_embedding])\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSHAPE2\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39marray(target_relation_embedding_list)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 39\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_relation_embedding_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m     41\u001b[0m scores \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     42\u001b[0m highest_scores_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 159 is different from 4096)"
     ]
    }
   ],
   "source": [
    "target_schema_dict = {}\n",
    "with open('schemas/webnlg_schema.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        target_schema_dict[row[0]] = row[1]\n",
    "\n",
    "retriever = SchemaRetriever(\n",
    "    target_schema_dict=target_schema_dict,\n",
    "    embedding_model='llama3.1',\n",
    ")\n",
    "\n",
    "retriever.retrieve_relevant_relations(\n",
    "    query_input_text='This indicates a specific date related to when an individual was born.',\n",
    "    top_k=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
